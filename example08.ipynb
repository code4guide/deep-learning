{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e018361e",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "9e2dba08",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/zz/qkcs__mj131c3rpjqqsq6kgh0000gn/T/ipykernel_71650/2646535498.py:31: FutureWarning: YF.download() has changed argument auto_adjust default to True\n",
      "  data = yf.download('AAPL', start='2023-01-01')\n",
      "[*********************100%***********************]  1 of 1 completed\n",
      "/Users/rhcproc/Documents/GitHub/deep-learning/venv/lib/python3.13/site-packages/ta/trend.py:1030: FutureWarning: Series.__setitem__ treating keys as positions is deprecated. In a future version, integer keys will always be treated as labels (consistent with DataFrame behavior). To set a value by position, use `ser.iloc[pos] = value`\n",
      "  self._psar[i] = high2\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best Parameters: {'max_depth': 20, 'n_estimators': 100}\n",
      "Acc Scores: [0.84955752 0.84033613 0.83050847 0.88333333 0.82142857]\n",
      "Acc Scores Mean: 0.8450328071831702\n"
     ]
    }
   ],
   "source": [
    "\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.model_selection import cross_val_score\n",
    "\n",
    "from sklearn.model_selection import GridSearchCV, RandomizedSearchCV\n",
    "\n",
    "import yfinance as yf\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "\n",
    "def get_ta_data(data):\n",
    "    from ta import add_all_ta_features\n",
    "    df = data\n",
    "\n",
    "    # 열 이름에서 'AAPL'을 제거\n",
    "    df.columns = [col[0] for col in df.columns]\n",
    "\n",
    "    df = df[['Open', 'High', 'Low', 'Close', 'Volume']]\n",
    "    # df.set_index('Datetime', inplace=True)\n",
    "    adf = add_all_ta_features(\n",
    "        df,\n",
    "        open=\"Open\", high=\"High\", low=\"Low\", close=\"Close\", volume=\"Volume\"\n",
    "    )\n",
    "    adf = adf.drop(\n",
    "        ['trend_psar_down', 'trend_psar_up'], axis=1\n",
    "    )\n",
    "    adf.dropna(inplace=True)\n",
    "    return adf\n",
    "\n",
    "data = yf.download('AAPL', start='2023-01-01')\n",
    "\n",
    "_X = data[['Open', 'High', 'Low', 'Close', 'Volume']]\n",
    "X = get_ta_data(_X)\n",
    "y = np.where(X['Close'].shift(-5) > X['Close'], 1, -1)\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, random_state=42)\n",
    "\n",
    "model = RandomForestClassifier(n_estimators=100, random_state=42)\n",
    "\n",
    "param_grid = {\n",
    "    'n_estimators': [100, 200, 300],\n",
    "    'max_depth': [10, 20, 30, 40, 50],\n",
    "}\n",
    "\n",
    "grid_search = GridSearchCV(model, param_grid, cv=5, scoring='accuracy')\n",
    "grid_search.fit(X_train, y_train)\n",
    "\n",
    "print(f'Best Parameters: {grid_search.best_params_}')\n",
    "model = RandomForestClassifier(**grid_search.best_params_)\n",
    "\n",
    "cvs = cross_val_score(model, X_train, y_train, cv=5, scoring='f1')\n",
    "\n",
    "print(f'Acc Scores: {cvs}')\n",
    "print(f'Acc Scores Mean: {cvs.mean()}')\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b896b037",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "283dfb05",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/zz/qkcs__mj131c3rpjqqsq6kgh0000gn/T/ipykernel_71650/899713394.py:71: FutureWarning: YF.download() has changed argument auto_adjust default to True\n",
      "  data = yf.download('AAPL', start='2023-01-01')\n",
      "[*********************100%***********************]  1 of 1 completed\n",
      "/Users/rhcproc/Documents/GitHub/deep-learning/venv/lib/python3.13/site-packages/ta/trend.py:1030: FutureWarning: Series.__setitem__ treating keys as positions is deprecated. In a future version, integer keys will always be treated as labels (consistent with DataFrame behavior). To set a value by position, use `ser.iloc[pos] = value`\n",
      "  self._psar[i] = high2\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using device: cpu\n",
      "\n",
      "===== Fold 1 =====\n",
      "Epoch [01] Train Loss: 0.6917  Val Loss: 0.6746\n",
      "Epoch [02] Train Loss: 0.6766  Val Loss: 0.6644\n",
      "Epoch [03] Train Loss: 0.6696  Val Loss: 0.6572\n",
      "Epoch [04] Train Loss: 0.6709  Val Loss: 0.6544\n",
      "Epoch [05] Train Loss: 0.6586  Val Loss: 0.6539\n",
      "Epoch [06] Train Loss: 0.6648  Val Loss: 0.6550\n",
      "Epoch [07] Train Loss: 0.6509  Val Loss: 0.6495\n",
      "Epoch [08] Train Loss: 0.6437  Val Loss: 0.6382\n",
      "Epoch [09] Train Loss: 0.6349  Val Loss: 0.6345\n",
      "Epoch [10] Train Loss: 0.6159  Val Loss: 0.6276\n",
      "Epoch [11] Train Loss: 0.6102  Val Loss: 0.6289\n",
      "Epoch [12] Train Loss: 0.5905  Val Loss: 0.6203\n",
      "Epoch [13] Train Loss: 0.5783  Val Loss: 0.6151\n",
      "Epoch [14] Train Loss: 0.5655  Val Loss: 0.6179\n",
      "Epoch [15] Train Loss: 0.5686  Val Loss: 0.6119\n",
      "Epoch [16] Train Loss: 0.5478  Val Loss: 0.6079\n",
      "Epoch [17] Train Loss: 0.5308  Val Loss: 0.5979\n",
      "Epoch [18] Train Loss: 0.5002  Val Loss: 0.5958\n",
      "Epoch [19] Train Loss: 0.5057  Val Loss: 0.5936\n",
      "Epoch [20] Train Loss: 0.5127  Val Loss: 0.5729\n",
      "Epoch [21] Train Loss: 0.4966  Val Loss: 0.5864\n",
      "Epoch [22] Train Loss: 0.4990  Val Loss: 0.6056\n",
      "Epoch [23] Train Loss: 0.4865  Val Loss: 0.5921\n",
      "Epoch [24] Train Loss: 0.4549  Val Loss: 0.5952\n",
      "Epoch [25] Train Loss: 0.4752  Val Loss: 0.5773\n",
      "Early stopping!\n",
      "Fold 1 F1 Score: 0.7377\n",
      "\n",
      "===== Fold 2 =====\n",
      "Epoch [01] Train Loss: 0.6918  Val Loss: 0.6865\n",
      "Epoch [02] Train Loss: 0.6751  Val Loss: 0.6844\n",
      "Epoch [03] Train Loss: 0.6672  Val Loss: 0.6832\n",
      "Epoch [04] Train Loss: 0.6650  Val Loss: 0.6822\n",
      "Epoch [05] Train Loss: 0.6576  Val Loss: 0.6787\n",
      "Epoch [06] Train Loss: 0.6469  Val Loss: 0.6794\n",
      "Epoch [07] Train Loss: 0.6383  Val Loss: 0.6799\n",
      "Epoch [08] Train Loss: 0.6326  Val Loss: 0.6813\n",
      "Epoch [09] Train Loss: 0.6241  Val Loss: 0.6852\n",
      "Epoch [10] Train Loss: 0.6103  Val Loss: 0.6847\n",
      "Early stopping!\n",
      "Fold 2 F1 Score: 0.6901\n",
      "\n",
      "===== Fold 3 =====\n",
      "Epoch [01] Train Loss: 0.6926  Val Loss: 0.6806\n",
      "Epoch [02] Train Loss: 0.6737  Val Loss: 0.6856\n",
      "Epoch [03] Train Loss: 0.6652  Val Loss: 0.6953\n",
      "Epoch [04] Train Loss: 0.6641  Val Loss: 0.6995\n",
      "Epoch [05] Train Loss: 0.6521  Val Loss: 0.7004\n",
      "Epoch [06] Train Loss: 0.6496  Val Loss: 0.6976\n",
      "Early stopping!\n",
      "Fold 3 F1 Score: 0.5755\n",
      "\n",
      "===== Fold 4 =====\n",
      "Epoch [01] Train Loss: 0.6911  Val Loss: 0.6911\n",
      "Epoch [02] Train Loss: 0.6747  Val Loss: 0.6907\n",
      "Epoch [03] Train Loss: 0.6678  Val Loss: 0.6903\n",
      "Epoch [04] Train Loss: 0.6584  Val Loss: 0.6901\n",
      "Epoch [05] Train Loss: 0.6486  Val Loss: 0.6854\n",
      "Epoch [06] Train Loss: 0.6411  Val Loss: 0.6851\n",
      "Epoch [07] Train Loss: 0.6285  Val Loss: 0.6821\n",
      "Epoch [08] Train Loss: 0.6213  Val Loss: 0.6832\n",
      "Epoch [09] Train Loss: 0.6051  Val Loss: 0.6789\n",
      "Epoch [10] Train Loss: 0.5934  Val Loss: 0.6754\n",
      "Epoch [11] Train Loss: 0.5902  Val Loss: 0.6793\n",
      "Epoch [12] Train Loss: 0.5818  Val Loss: 0.6710\n",
      "Epoch [13] Train Loss: 0.5586  Val Loss: 0.6714\n",
      "Epoch [14] Train Loss: 0.5536  Val Loss: 0.6652\n",
      "Epoch [15] Train Loss: 0.5405  Val Loss: 0.6558\n",
      "Epoch [16] Train Loss: 0.5385  Val Loss: 0.6727\n",
      "Epoch [17] Train Loss: 0.5304  Val Loss: 0.6557\n",
      "Epoch [18] Train Loss: 0.5130  Val Loss: 0.6708\n",
      "Epoch [19] Train Loss: 0.4998  Val Loss: 0.6514\n",
      "Epoch [20] Train Loss: 0.4692  Val Loss: 0.6504\n",
      "Epoch [21] Train Loss: 0.4707  Val Loss: 0.6591\n",
      "Epoch [22] Train Loss: 0.4389  Val Loss: 0.6475\n",
      "Epoch [23] Train Loss: 0.4514  Val Loss: 0.6406\n",
      "Epoch [24] Train Loss: 0.4714  Val Loss: 0.6628\n",
      "Epoch [25] Train Loss: 0.4251  Val Loss: 0.6491\n",
      "Epoch [26] Train Loss: 0.4447  Val Loss: 0.6369\n",
      "Epoch [27] Train Loss: 0.4251  Val Loss: 0.6361\n",
      "Epoch [28] Train Loss: 0.4415  Val Loss: 0.6075\n",
      "Epoch [29] Train Loss: 0.4018  Val Loss: 0.6400\n",
      "Epoch [30] Train Loss: 0.3965  Val Loss: 0.6150\n",
      "Fold 4 F1 Score: 0.7481\n",
      "\n",
      "===== Fold 5 =====\n",
      "Epoch [01] Train Loss: 0.6881  Val Loss: 0.6849\n",
      "Epoch [02] Train Loss: 0.6786  Val Loss: 0.6811\n",
      "Epoch [03] Train Loss: 0.6702  Val Loss: 0.6811\n",
      "Epoch [04] Train Loss: 0.6591  Val Loss: 0.6748\n",
      "Epoch [05] Train Loss: 0.6523  Val Loss: 0.6713\n",
      "Epoch [06] Train Loss: 0.6478  Val Loss: 0.6710\n",
      "Epoch [07] Train Loss: 0.6374  Val Loss: 0.6659\n",
      "Epoch [08] Train Loss: 0.6276  Val Loss: 0.6695\n",
      "Epoch [09] Train Loss: 0.6119  Val Loss: 0.6690\n",
      "Epoch [10] Train Loss: 0.6031  Val Loss: 0.6715\n",
      "Epoch [11] Train Loss: 0.5910  Val Loss: 0.6695\n",
      "Epoch [12] Train Loss: 0.5758  Val Loss: 0.6760\n",
      "Early stopping!\n",
      "Fold 5 F1 Score: 0.6240\n",
      "\n",
      "===== Cross-Validation 결과 =====\n",
      "F1 Scores: [0.7377049180327869, 0.6901408450704225, 0.5755395683453237, 0.7480916030534351, 0.624]\n",
      "F1 Mean: 0.6750953869003937\n",
      "Epoch [01] Train Loss: 0.6856  Val Loss: 0.6901\n",
      "Epoch [02] Train Loss: 0.6693  Val Loss: 0.6881\n",
      "Epoch [03] Train Loss: 0.6679  Val Loss: 0.6860\n",
      "Epoch [04] Train Loss: 0.6531  Val Loss: 0.6870\n",
      "Epoch [05] Train Loss: 0.6517  Val Loss: 0.6896\n",
      "Epoch [06] Train Loss: 0.6415  Val Loss: 0.6886\n",
      "Epoch [07] Train Loss: 0.6357  Val Loss: 0.6797\n",
      "Epoch [08] Train Loss: 0.6150  Val Loss: 0.6788\n",
      "Epoch [09] Train Loss: 0.6116  Val Loss: 0.6829\n",
      "Epoch [10] Train Loss: 0.6007  Val Loss: 0.6760\n",
      "Epoch [11] Train Loss: 0.5913  Val Loss: 0.6731\n",
      "Epoch [12] Train Loss: 0.5855  Val Loss: 0.6650\n",
      "Epoch [13] Train Loss: 0.5751  Val Loss: 0.6595\n",
      "Epoch [14] Train Loss: 0.5519  Val Loss: 0.6505\n",
      "Epoch [15] Train Loss: 0.5455  Val Loss: 0.6505\n",
      "Epoch [16] Train Loss: 0.5298  Val Loss: 0.6472\n",
      "Epoch [17] Train Loss: 0.5166  Val Loss: 0.6565\n",
      "Epoch [18] Train Loss: 0.5115  Val Loss: 0.6457\n",
      "Epoch [19] Train Loss: 0.4856  Val Loss: 0.6463\n",
      "Epoch [20] Train Loss: 0.4980  Val Loss: 0.6482\n",
      "Epoch [21] Train Loss: 0.4783  Val Loss: 0.6391\n",
      "Epoch [22] Train Loss: 0.4726  Val Loss: 0.6521\n",
      "Epoch [23] Train Loss: 0.4623  Val Loss: 0.6580\n",
      "Epoch [24] Train Loss: 0.4574  Val Loss: 0.6302\n",
      "Epoch [25] Train Loss: 0.4570  Val Loss: 0.6386\n",
      "Epoch [26] Train Loss: 0.4131  Val Loss: 0.6280\n",
      "Epoch [27] Train Loss: 0.4286  Val Loss: 0.6410\n",
      "Epoch [28] Train Loss: 0.4259  Val Loss: 0.6233\n",
      "Epoch [29] Train Loss: 0.4218  Val Loss: 0.6224\n",
      "Epoch [30] Train Loss: 0.3928  Val Loss: 0.6521\n",
      "\n",
      "===== Test 성능 =====\n",
      "Test F1 Score: 0.7407\n"
     ]
    }
   ],
   "source": [
    "from sklearn.model_selection import train_test_split, KFold\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.metrics import f1_score\n",
    "\n",
    "from ta import add_all_ta_features\n",
    "import yfinance as yf\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "from torch.utils.data import TensorDataset, DataLoader\n",
    "\n",
    "# =========================\n",
    "# 1. TA feature 생성 함수\n",
    "# =========================\n",
    "def get_ta_data(data: pd.DataFrame) -> pd.DataFrame:\n",
    "    df = data.copy()\n",
    "\n",
    "    # 멀티인덱스 컬럼 처리: ('AAPL','Open') -> 'Open' 으로 변경\n",
    "    if isinstance(df.columns, pd.MultiIndex):\n",
    "        # MultiIndex의 경우: level 0은 티커명, level 1은 실제 컬럼명\n",
    "        # 두 레벨 모두 확인해서 올바른 레벨 선택\n",
    "        level_0 = df.columns.get_level_values(0).unique()\n",
    "        level_1 = df.columns.get_level_values(1).unique()\n",
    "        \n",
    "        # level 1에 'Open', 'High' 등이 있으면 level 1 사용\n",
    "        if any(col in level_1 for col in ['Open', 'High', 'Low', 'Close', 'Volume']):\n",
    "            df.columns = df.columns.get_level_values(1)\n",
    "        # level 0에 있으면 level 0 사용 (드문 경우)\n",
    "        elif any(col in level_0 for col in ['Open', 'High', 'Low', 'Close', 'Volume']):\n",
    "            df.columns = df.columns.get_level_values(0)\n",
    "        else:\n",
    "            # 둘 다 아니면 level 1 사용 (기본값)\n",
    "            df.columns = df.columns.get_level_values(1)\n",
    "    else:\n",
    "        # 일반 Index인데 튜플 형태인 경우 처리\n",
    "        if len(df.columns) > 0 and isinstance(df.columns[0], tuple):\n",
    "            df.columns = [col[1] if len(col) > 1 else col[0] for col in df.columns]\n",
    "\n",
    "    # 필요한 컬럼만 선택\n",
    "    required_cols = ['Open', 'High', 'Low', 'Close', 'Volume']\n",
    "    \n",
    "    # 컬럼이 존재하는지 확인\n",
    "    missing_cols = [col for col in required_cols if col not in df.columns]\n",
    "    if missing_cols:\n",
    "        # 디버깅 정보 출력\n",
    "        print(f\"디버깅: 컬럼 타입 = {type(df.columns)}\")\n",
    "        print(f\"디버깅: 원본 컬럼 = {list(data.columns)}\")\n",
    "        print(f\"디버깅: 변환 후 컬럼 = {list(df.columns)}\")\n",
    "        raise ValueError(f\"필요한 컬럼을 찾을 수 없습니다: {missing_cols}. 사용 가능한 컬럼: {list(df.columns)}\")\n",
    "    \n",
    "    df = df[required_cols]\n",
    "\n",
    "    adf = add_all_ta_features(\n",
    "        df,\n",
    "        open=\"Open\", high=\"High\", low=\"Low\", close=\"Close\", volume=\"Volume\"\n",
    "    )\n",
    "\n",
    "    # 원래 코드에 있던 PSAR 컬럼 제거 (존재할 때만)\n",
    "    drop_cols = [c for c in ['trend_psar_down', 'trend_psar_up'] if c in adf.columns]\n",
    "    if drop_cols:\n",
    "        adf = adf.drop(drop_cols, axis=1)\n",
    "\n",
    "    adf.dropna(inplace=True)\n",
    "    return adf\n",
    "\n",
    "# =========================\n",
    "# 2. 데이터 다운로드 & 전처리\n",
    "# =========================\n",
    "data = yf.download('AAPL', start='2023-01-01')\n",
    "\n",
    "X_df = get_ta_data(data)\n",
    "\n",
    "# 레이블: 5일 뒤 종가가 지금보다 높으면 1, 아니면 0\n",
    "y = np.where(X_df['Close'].shift(-5) > X_df['Close'], 1, 0)\n",
    "\n",
    "# shift로 생긴 NaN 제거\n",
    "mask = ~pd.isna(y)\n",
    "X_df = X_df[mask]\n",
    "y = y[mask]\n",
    "\n",
    "X = X_df.values.astype(np.float32)\n",
    "y = y.astype(int)\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(\n",
    "    X, y, test_size=0.2, random_state=42, stratify=y\n",
    ")\n",
    "\n",
    "scaler = StandardScaler()\n",
    "X_train_scaled = scaler.fit_transform(X_train).astype(np.float32)\n",
    "X_test_scaled = scaler.transform(X_test).astype(np.float32)\n",
    "\n",
    "input_dim = X_train_scaled.shape[1]\n",
    "\n",
    "# =========================\n",
    "# 3. PyTorch 모델 정의\n",
    "# =========================\n",
    "class MLP(nn.Module):\n",
    "    def __init__(self, input_dim: int):\n",
    "        super().__init__()\n",
    "        self.net = nn.Sequential(\n",
    "            nn.Linear(input_dim, 128),\n",
    "            nn.ReLU(),\n",
    "            nn.Dropout(0.3),\n",
    "            nn.Linear(128, 64),\n",
    "            nn.ReLU(),\n",
    "            nn.Dropout(0.3),\n",
    "            nn.Linear(64, 1),  # binary classification (logit)\n",
    "        )\n",
    "\n",
    "    def forward(self, x):\n",
    "        # 출력: (batch,) 로 맞춰줌\n",
    "        return self.net(x).squeeze(-1)\n",
    "\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "print(\"Using device:\", device)\n",
    "\n",
    "# =========================\n",
    "# 4. 학습/평가 유틸 함수\n",
    "# =========================\n",
    "def train_one_fold(model, train_loader, val_loader, device,\n",
    "                   epochs=30, lr=1e-3, patience=5):\n",
    "    criterion = nn.BCEWithLogitsLoss()\n",
    "    optimizer = torch.optim.Adam(model.parameters(), lr=lr)\n",
    "\n",
    "    best_val_loss = float('inf')\n",
    "    best_state = None\n",
    "    patience_cnt = 0\n",
    "\n",
    "    for epoch in range(1, epochs + 1):\n",
    "        # ----- Train -----\n",
    "        model.train()\n",
    "        train_loss = 0.0\n",
    "        for xb, yb in train_loader:\n",
    "            xb = xb.to(device)\n",
    "            yb = yb.to(device)\n",
    "\n",
    "            optimizer.zero_grad()\n",
    "            logits = model(xb)\n",
    "            loss = criterion(logits, yb)\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "\n",
    "            train_loss += loss.item() * xb.size(0)\n",
    "\n",
    "        train_loss /= len(train_loader.dataset)\n",
    "\n",
    "        # ----- Validation -----\n",
    "        model.eval()\n",
    "        val_loss = 0.0\n",
    "        with torch.no_grad():\n",
    "            for xb, yb in val_loader:\n",
    "                xb = xb.to(device)\n",
    "                yb = yb.to(device)\n",
    "                logits = model(xb)\n",
    "                loss = criterion(logits, yb)\n",
    "                val_loss += loss.item() * xb.size(0)\n",
    "\n",
    "        val_loss /= len(val_loader.dataset)\n",
    "\n",
    "        print(f\"Epoch [{epoch:02d}] \"\n",
    "              f\"Train Loss: {train_loss:.4f}  Val Loss: {val_loss:.4f}\")\n",
    "\n",
    "        # Early stopping 체크\n",
    "        if val_loss < best_val_loss:\n",
    "            best_val_loss = val_loss\n",
    "            best_state = model.state_dict()\n",
    "            patience_cnt = 0\n",
    "        else:\n",
    "            patience_cnt += 1\n",
    "            if patience_cnt >= patience:\n",
    "                print(\"Early stopping!\")\n",
    "                break\n",
    "\n",
    "    # 가장 좋은 상태로 복구\n",
    "    if best_state is not None:\n",
    "        model.load_state_dict(best_state)\n",
    "\n",
    "    return model\n",
    "\n",
    "\n",
    "def predict_proba(model, loader, device):\n",
    "    model.eval()\n",
    "    probs_list = []\n",
    "    with torch.no_grad():\n",
    "        for xb, _ in loader:\n",
    "            xb = xb.to(device)\n",
    "            logits = model(xb)\n",
    "            probs = torch.sigmoid(logits)\n",
    "            probs_list.append(probs.cpu().numpy())\n",
    "    return np.concatenate(probs_list, axis=0)\n",
    "\n",
    "# =========================\n",
    "# 5. K-Fold Cross Validation\n",
    "# =========================\n",
    "kf = KFold(n_splits=5, shuffle=True, random_state=42)\n",
    "batch_size = 64\n",
    "\n",
    "fold_f1_scores = []\n",
    "\n",
    "for fold, (tr_idx, val_idx) in enumerate(kf.split(X_train_scaled), 1):\n",
    "    print(f\"\\n===== Fold {fold} =====\")\n",
    "\n",
    "    X_tr = X_train_scaled[tr_idx]\n",
    "    y_tr = y_train[tr_idx]\n",
    "    X_val = X_train_scaled[val_idx]\n",
    "    y_val = y_train[val_idx]\n",
    "\n",
    "    # Torch Tensor로 변환\n",
    "    X_tr_tensor = torch.tensor(X_tr, dtype=torch.float32)\n",
    "    y_tr_tensor = torch.tensor(y_tr, dtype=torch.float32)  # BCEWithLogits → float\n",
    "    X_val_tensor = torch.tensor(X_val, dtype=torch.float32)\n",
    "    y_val_tensor = torch.tensor(y_val, dtype=torch.float32)\n",
    "\n",
    "    train_ds = TensorDataset(X_tr_tensor, y_tr_tensor)\n",
    "    val_ds = TensorDataset(X_val_tensor, y_val_tensor)\n",
    "\n",
    "    train_loader = DataLoader(train_ds, batch_size=batch_size, shuffle=True)\n",
    "    val_loader = DataLoader(val_ds, batch_size=batch_size, shuffle=False)\n",
    "\n",
    "    model = MLP(input_dim).to(device)\n",
    "\n",
    "    # 한 fold 학습\n",
    "    model = train_one_fold(model, train_loader, val_loader, device,\n",
    "                           epochs=30, lr=1e-3, patience=5)\n",
    "\n",
    "    # validation에 대한 F1 스코어\n",
    "    val_loader_for_pred = DataLoader(val_ds, batch_size=batch_size, shuffle=False)\n",
    "    val_probs = predict_proba(model, val_loader_for_pred, device)\n",
    "    val_pred = (val_probs > 0.5).astype(int)\n",
    "\n",
    "    f1 = f1_score(y_val, val_pred)\n",
    "    fold_f1_scores.append(f1)\n",
    "    print(f\"Fold {fold} F1 Score: {f1:.4f}\")\n",
    "\n",
    "print(\"\\n===== Cross-Validation 결과 =====\")\n",
    "print(\"F1 Scores:\", fold_f1_scores)\n",
    "print(\"F1 Mean:\", np.mean(fold_f1_scores))\n",
    "\n",
    "# =========================\n",
    "# 6. 최종 모델 (train 전체로 학습 후 test 평가)\n",
    "# =========================\n",
    "# train 내부에서 다시 80/20으로 나눠서 val 사용\n",
    "X_tr_all, X_val_all, y_tr_all, y_val_all = train_test_split(\n",
    "    X_train_scaled, y_train, test_size=0.2, random_state=42, stratify=y_train\n",
    ")\n",
    "\n",
    "X_tr_all_t = torch.tensor(X_tr_all, dtype=torch.float32)\n",
    "y_tr_all_t = torch.tensor(y_tr_all, dtype=torch.float32)\n",
    "X_val_all_t = torch.tensor(X_val_all, dtype=torch.float32)\n",
    "y_val_all_t = torch.tensor(y_val_all, dtype=torch.float32)\n",
    "\n",
    "train_ds_all = TensorDataset(X_tr_all_t, y_tr_all_t)\n",
    "val_ds_all = TensorDataset(X_val_all_t, y_val_all_t)\n",
    "\n",
    "train_loader_all = DataLoader(train_ds_all, batch_size=batch_size, shuffle=True)\n",
    "val_loader_all = DataLoader(val_ds_all, batch_size=batch_size, shuffle=False)\n",
    "\n",
    "final_model = MLP(input_dim).to(device)\n",
    "final_model = train_one_fold(final_model, train_loader_all, val_loader_all, device,\n",
    "                             epochs=30, lr=1e-3, patience=5)\n",
    "\n",
    "# Test 세트 평가\n",
    "X_test_t = torch.tensor(X_test_scaled, dtype=torch.float32)\n",
    "y_test_t = torch.tensor(y_test, dtype=torch.float32)\n",
    "\n",
    "test_ds = TensorDataset(X_test_t, y_test_t)\n",
    "test_loader = DataLoader(test_ds, batch_size=batch_size, shuffle=False)\n",
    "\n",
    "test_probs = predict_proba(final_model, test_loader, device)\n",
    "test_pred = (test_probs > 0.5).astype(int)\n",
    "\n",
    "test_f1 = f1_score(y_test, test_pred)\n",
    "print(\"\\n===== Test 성능 =====\")\n",
    "print(f\"Test F1 Score: {test_f1:.4f}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6a69a06b",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e379e56b",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "123d3f50",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "aa60793b",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "08afdc3f",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
